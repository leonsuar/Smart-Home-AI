# Usa una imagen base con Python y herramientas de desarrollo basada en Debian Bullseye
FROM python:3.9-slim-bullseye

# Establece el directorio de trabajo dentro del contenedor.
# Los modelos se guardarán en /app/models (volumen), y el código en /app_code (montado desde el host).
WORKDIR /app_code

# Instala las dependencias básicas necesarias.
# Ya no necesitamos build-essential, cmake, git, libblas-dev, liblapack-dev, libopenblas-dev, pkg-config
# porque transformers no compila llama-cpp-python.
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    python-is-python3 && rm -rf /var/lib/apt/lists/*

# Copia los archivos de requisitos e instálalos.
# requirements_pytorch.txt ahora contendrá 'transformers' y 'torch'.
COPY requirements_pytorch.txt .
RUN pip install --no-cache-dir -r requirements_pytorch.txt

# Copia el código de la aplicación (pytorch_model_server.py)
COPY pytorch_model_server.py .

# Expone el puerto que usará la aplicación Flask
EXPOSE 5001

# Comando para ejecutar la aplicación Flask
# Asegúrate de que el script se ejecute desde /app_code
CMD ["python", "pytorch_model_server.py"]
