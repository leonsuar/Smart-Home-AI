version: '3.8'

services:
  main_app:
    build:
      context: . # Contexto de construcción en la raíz del proyecto
      dockerfile: main_app/Dockerfile_app # Ruta al Dockerfile relativa al contexto
    volumes:
      # Montamos los directorios directamente para desarrollo local
      - ./main_app:/app/main_app
      - ./knowledge:/app/knowledge
      - ./core_logic:/app/core_logic # Montado para main_app
    environment:
      - FLASK_ENV=development
      - PYTHONPATH=/app # ¡Añadido para que Python encuentre core_logic!
      - GEMINI_API_KEY=AIzaSyA_iF4rVbLVprHCbsiSGshFxFu8CXSsGvU
      # Las variables MQTT/ML_SERVER se leen de config.json en tu código,
      # por lo que no se necesitan aquí si el network_mode es host.
    network_mode: host # El contenedor usa directamente los puertos del host
    depends_on:
      - ml_server
    dns: # Configuración DNS para NTP y resolución de nombres
      - 192.168.1.10 # Tu servidor NTP/DNS local
      - 8.8.8.8      # DNS de respaldo (Google DNS)

  ml_server:
    build:
      context: . # ¡También el contexto de construcción es la raíz del proyecto!
      dockerfile: ml_server/Dockerfile_ml # Ruta al Dockerfile relativa al nuevo contexto
    volumes:
      # Montamos los directorios directamente para desarrollo local
      - ./ml_server:/app/ml_server # Cambiado el destino a /app/ml_server para consistencia
      - ./core_logic:/app/core_logic # ¡Montado para ml_server también!
    environment:
      - FLASK_ENV=development
      - PYTHONPATH=/app # ¡Añadido para que Python encuentre core_logic!
    network_mode: host
    dns: # Configuración DNS para NTP y resolución de nombres
      - 192.168.1.10 # Tu servidor NTP/DNS local
      - 8.8.8.8      # DNS de respaldo (Google DNS)
